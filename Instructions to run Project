# How to Run the Project?
## 1. Setup Environment
Make sure you have Python installed (preferably 3.7+).

Install required libraries:
pip install numpy pandas tensorflow pillow scikit-learn matplotlib opencv-python

## 2. Prepare Your Dataset
- Place your CSV file (cleaned_words_mapped.csv) with columns word_id and transcription on your local machine.
- Store images in the specified folder structure inside iam_words/words/ as expected by your join_path() function.

## 3. Train the Recognition Model
### Run the first script you provided to:

- Load and preprocess images and transcription data.
- Tokenize text and pad sequences.
- Build the multimodal model (image + text).
- Train the model on your dataset.
- Save the trained model (complete_model.h5), tokenizer (tokenizer.pkl), and training history (history.pkl).
- Visualize training curves.
### Note: Training will require a GPU for speed and might take a few hours depending on dataset size.

## 4. Segment Words from Handwritten Prescription Image
### Use the second script for word segmentation from prescription images:

- Upload an image using Google Colab file uploader or load from disk.
- Convert to grayscale and apply adaptive thresholding.
- Dilate to join words (not letters).
- Detect contours as word bounding boxes.
- Extract and save individual word images in a folder (Segmented_Words).
- Display word bounding boxes for verification.

## 5. Load Model and Tokenizer for Prediction
- Load your saved model and tokenizer files from disk.
- Define preprocessing functions to prepare input images and text for the model.
- Use your predict_on_image() or predict_on_folder() functions to get predictions for segmented words.

## 6. Run Predictions on Segmented Words
- Pass the folder containing segmented word images (Segmented_Words) to the prediction function.
- Provide a sample or heuristic text input to the text input branch of the model (e.g., some guess about the word context or fixed placeholder).
- View the top-k predictions for each word image.

## 7. Cleanup
Clear TensorFlow session and collect garbage to free memory after prediction/training.
